#получение хтмл кода страницы
# from bs4 import BeautifulSoup
# import requests
# url = 'https://www.yahoo.com/'
# res = requests.get(url)
# soup = BeautifulSoup(res.text,'html.parser')
# #print(soup)


#получение ссылки на страницу
# from urllib.request import urlopen
# url = 'https://www.yahoo.com/'
# page = urlopen(url)
# html_code = page.read().decode('utf-8')
# start = html_code.find('href="') + 6
# end = html_code.find('">More')
# link = html_code[start:end]
# print(link)


#вывод мусора(ссылок, текста и всякой информации)
# from urllib.request import urlopen
# import re
# url = 'https://www.yahoo.com/'
# page = urlopen(url)
# html_code = page.read().decode('utf-8')
# link = r'(https?://\S+)(?=")'
# print(re.findall(link, html_code))

#Я получаю список ссылок
# from bs4 import BeautifulSoup
# from urllib.request import urlopen
# url = 'https://www.yahoo.com'
# page = urlopen(url)
# html = page.read().decode('utf-8')
# soup = BeautifulSoup(html, 'html.parser')
# links = set()
# for link in soup.find_all('a'):
#     l = link.get('href')
#     if l != None and l.startswith('https'):
#         links.add(l)
# for link in links:
#     print(link)

#где то тут получение инфы об RSS
import requests, re
from bs4 import BeautifulSoup
website_links = ["https://www.diepresse.com/",
"https://www.sueddeutsche.de/",
"https://www.berliner-zeitung.de/",
"https://www.aargauerzeitung.ch/",
"https://www.luzernerzeitung.ch/",
"https://www.nzz.ch/technologie/",
"https://www.spiegel.de/",
"https://www.blick.ch/wirtschaft/"]
rss_feeds = []
def check_for_real_rss(url):
    base_url = re.search('^(?:https?:\/\/)?(?:[^@\/\n]+@)?(?:www\.)?([^:\/\n]+)',url).group(0)
    r = requests.get(url)
    soup = BeautifulSoup(r.text)
    for e in soup.select('[type="application/rss+xml"],a[href*=".rss"],a[href$="feed"]'):
        if e.get('href').startswith('/'):
            rss = (base_url+e.get('href'))
        else:
            rss = (e.get('href'))
        if 'xml' in requests.get(rss).headers.get('content-type'):
            rss_feeds.append(rss)
for url in website_links:
    soup = BeautifulSoup(requests.get(url).text)
    for e in soup.select('a[href*="rss"],a[href*="/feed"],a:-soup-contains-own("RSS")'):
        if e.get('href').startswith('/'):
            check_for_real_rss(url.strip('/')+e.get('href'))
        else:
            check_for_real_rss(e.get('href'))
set(rss_feeds)